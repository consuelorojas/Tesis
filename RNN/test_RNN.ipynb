{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x115adbe30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#files\n",
    "import sys\n",
    "#from os import listdir\n",
    "sys.path.append('../data')\n",
    "sys.path.append('../Librerias')\n",
    "#from os.path import isfile, join\n",
    "\n",
    "#own libs\n",
    "import utils\n",
    "import caract as dc\n",
    "import dataset as ds\n",
    "from models import SimpleRNN, LSTM, MLP\n",
    "#from lstm_models import LSTM\n",
    "import utils_2 as ut2\n",
    "from traindata import trainData\n",
    "import errores as er\n",
    "\n",
    "\n",
    "\n",
    "#data and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, root_mean_squared_error, r2_score\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os, errno\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "\n",
    "np.random.seed(seed=77)\n",
    "torch.manual_seed(77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         0.006094\n",
      "1         0.006132\n",
      "2         0.006056\n",
      "3         0.006018\n",
      "4         0.006170\n",
      "            ...   \n",
      "599995    0.007766\n",
      "599996    0.007741\n",
      "599997    0.007761\n",
      "599998    0.007748\n",
      "599999    0.007755\n",
      "Name: Amplitude, Length: 600000, dtype: float64\n",
      "0         0.006094\n",
      "1         0.006132\n",
      "2         0.006056\n",
      "3         0.006018\n",
      "4         0.006170\n",
      "            ...   \n",
      "599995    0.007766\n",
      "599996    0.007741\n",
      "599997    0.007761\n",
      "599998    0.007748\n",
      "599999    0.007755\n",
      "Name: Amplitude, Length: 600000, dtype: float64\n",
      "0         0.006094\n",
      "1         0.006132\n",
      "2         0.006056\n",
      "3         0.006018\n",
      "4         0.006170\n",
      "            ...   \n",
      "599995    0.007766\n",
      "599996    0.007741\n",
      "599997    0.007761\n",
      "599998    0.007748\n",
      "599999    0.007755\n",
      "Name: Amplitude, Length: 600000, dtype: float64\n",
      "0         0.006094\n",
      "1         0.006132\n",
      "2         0.006056\n",
      "3         0.006018\n",
      "4         0.006170\n",
      "            ...   \n",
      "599995    0.007766\n",
      "599996    0.007741\n",
      "599997    0.007761\n",
      "599998    0.007748\n",
      "599999    0.007755\n",
      "Name: Amplitude, Length: 600000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#fpath = \"/Users/consu/OneDrive/Documentos/GitHub/Tesis/data/low/\"\n",
    "#fpath = \"/Users/granosftp/Documents/GitHub/Tesis/data/low/\"\n",
    "fpath = '/Users/falconlab/Documents/GitHub/Tesis/data/low/'\n",
    "fname = \"file1_080124.mat\"\n",
    "#cutoff = [8/1000, 11/1000]\n",
    "\n",
    "data = trainData(fpath, fname, 'Amplitude')\n",
    "train, val, test = data.split_data('Amplitude')\n",
    "\n",
    "import copy\n",
    "\n",
    "train = utils.subsample(train, 2)\n",
    "test = utils.subsample(test, 2)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train.reshape(-1, 1))\n",
    "test_scaled = scaler.transform(test.reshape(-1, 1))\n",
    "\n",
    "test = copy.deepcopy(test_scaled)\n",
    "\n",
    "x_train, y_train = ut2.create_sequences(train_scaled[:], 1000, 1)\n",
    "x_test, y_test = ut2.create_sequences(test_scaled, 1000, 1)\n",
    "\n",
    "x_train = torch.from_numpy(x_train.astype(np.float32)).squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size = x_train.shape[-1]\n",
    "out_size = 1\n",
    "hid_size = 3\n",
    "num_layers = 1\n",
    "\n",
    "\n",
    "model = SimpleRNN(in_size, hid_size, out_size, num_layers)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'earlystop_187.pth'\n",
    "utils.resume(model, optimizer, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **50 steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 50\n",
    "x_test , y_test = ut2.create_sequences(test, 1000, steps)\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32)).squeeze()\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32)).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43951/43951 [05:08<00:00, 142.43it/s]\n"
     ]
    }
   ],
   "source": [
    "test50 = ut2.rollingWindowPrediction(model, x_test, steps)\n",
    "np.savetxt(\"test50_RNN.csv\", test50, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.09710110882706069\n",
      "Mean Absolute Percentage Error: 1.376685290497444\n",
      "R2 Score: -8.477420081987562\n",
      "Root Mean Squared Error: 0.31012731976279934\n"
     ]
    }
   ],
   "source": [
    "mse, mape, r2, rmse = er.calculate_errors(test50, y_test)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Percentage Error: {mape}')\n",
    "print(f'R2 Score: {r2}')\n",
    "print(f'Root Mean Squared Error: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **100 steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 100\n",
    "x_test , y_test = ut2.create_sequences(test, 1000, steps)\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32)).squeeze()\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43901/43901 [10:26<00:00, 70.08it/s]\n"
     ]
    }
   ],
   "source": [
    "test100 = ut2.rollingWindowPrediction(model, x_test, steps)\n",
    "np.savetxt(\"test100_RNN.csv\", test100, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.06549347928686731\n",
      "Mean Absolute Percentage Error: 1.0189720192590013\n",
      "R2 Score: -5.738326952086253\n",
      "Root Mean Squared Error: 0.24241807593182435\n"
     ]
    }
   ],
   "source": [
    "mse, mape, r2, rmse = er.calculate_errors(test100, y_test)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Percentage Error: {mape}')\n",
    "print(f'R2 Score: {r2}')\n",
    "print(f'Root Mean Squared Error: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **500 steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 500\n",
    "x_test , y_test = ut2.create_sequences(test, 1000, steps)\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32)).squeeze()\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43501/43501 [1:10:04<00:00, 10.35it/s]\n"
     ]
    }
   ],
   "source": [
    "test500 = ut2.rollingWindowPrediction(model, x_test, steps)\n",
    "np.savetxt(\"test500_RNN.csv\", test500, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.04472074623771752\n",
      "Mean Absolute Percentage Error: 0.7980173659486399\n",
      "R2 Score: -4.373742639492199\n",
      "Root Mean Squared Error: 0.19971637431062197\n"
     ]
    }
   ],
   "source": [
    "mse, mape, r2, rmse = er.calculate_errors(test500, y_test)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Percentage Error: {mape}')\n",
    "print(f'R2 Score: {r2}')\n",
    "print(f'Root Mean Squared Error: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1000 steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 1000\n",
    "x_test , y_test = ut2.create_sequences(test, 1000, steps)\n",
    "x_test = torch.from_numpy(x_test.astype(np.float32)).squeeze()\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 40642/43001 [2:11:07<07:25,  5.29it/s]  IOStream.flush timed out\n",
      "100%|██████████| 43001/43001 [2:19:18<00:00,  5.14it/s]  \n"
     ]
    }
   ],
   "source": [
    "test1000 = ut2.rollingWindowPrediction(model, x_test, steps)\n",
    "np.savetxt(\"test1000_RNN.csv\", test1000, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.06242700525649339\n",
      "Mean Absolute Percentage Error: 0.9300775890304755\n",
      "R2 Score: -7.131219953915073\n",
      "Root Mean Squared Error: 0.2369488930861443\n"
     ]
    }
   ],
   "source": [
    "mse, mape, r2, rmse = er.calculate_errors(test1000, y_test)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Percentage Error: {mape}')\n",
    "print(f'R2 Score: {r2}')\n",
    "print(f'Root Mean Squared Error: {rmse}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
