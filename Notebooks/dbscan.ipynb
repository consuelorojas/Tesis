{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "\n",
    "# For visualizing the data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# For data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Librerias')\n",
    "import dataset as ds\n",
    "#no sé porqué no funciona cuando lo tengo en la carpeta de clusters\n",
    "#pero si funciona cuando esta solo en la de notebooks,,, raro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "fpath = \"/Users/granosftp/Documents/GitHub/Tesis/data/\"\n",
    "fname = \"datosconsu_021023_bajos.mat\"\n",
    "cutoff = [8/1000, 11/1000]\n",
    "\n",
    "set =  ds.MatFileToDataFrame(fpath, fname)\n",
    "df = set.get_dataframe(cutoff)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude_env = np.abs(df['Hilbert Transform'])\n",
    "inst_phase =  np.unwrap(np.angle(df['Hilbert Transform']))\n",
    "inst_freq = (np.diff(inst_phase)/(2.0*np.pi)*1000)\n",
    "diff_phase =  np.diff(inst_phase)\n",
    "mean_phase = np.mean(diff_phase)\n",
    "diff_phase = np.insert(diff_phase, 0, 0)  \n",
    "df['Amplitude Envelope'] = amplitude_env\n",
    "df['Instantaneous Phase'] = inst_phase\n",
    "\n",
    "#filtro al gradiente de fase\n",
    "\n",
    "cutoff = 0.1\n",
    "order = 4\n",
    "\n",
    "b,a = signal.butter(order, cutoff, btype='low')\n",
    "grad_phase = signal.filtfilt(b, a, diff_phase-mean_phase)\n",
    "\n",
    "df['Gradient Phase'] = grad_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_end_defectos = [\n",
    "    [25014, 25042],\n",
    "    [27460, 27487],\n",
    "    [35630, 35658],\n",
    "    [37207, 37236],\n",
    "    [48343, 48372],\n",
    "    [57421, 57450],\n",
    "    [61722, 61750],\n",
    "    [78988, 79016],\n",
    "    [82306, 82336],\n",
    "    [84344, 84373],\n",
    "    [97845, 97875], #10\n",
    "    [99883, 99914], \n",
    "    [101083, 101111],\n",
    "    [131884, 131912],\n",
    "    [165590, 165619],\n",
    "    [166234, 166264],\n",
    "    [183081, 183109],\n",
    "    [187677, 187705],\n",
    "    [203502, 203530],\n",
    "    [219482, 219510],\n",
    "    [235509, 235537], #20\n",
    "    [275603, 275633],\n",
    "    [277908, 277936],\n",
    "    [301722, 301753],\n",
    "    [322041, 322070],\n",
    "    [322422, 322450],\n",
    "    [339137, 339166],\n",
    "    [393906, 393935],\n",
    "    [395396, 395424],\n",
    "    [396716, 396746],\n",
    "    [412940, 412969], #30\n",
    "    [413358, 413386], \n",
    "    [430261, 430289],\n",
    "    [444404, 444433],\n",
    "    [453962, 453990],\n",
    "    [456065, 456095],\n",
    "    [456863, 456892],\n",
    "    [457187, 457215],\n",
    "    [457390, 457419],\n",
    "    [470756, 470783],\n",
    "    [474540, 474568], #40\n",
    "    [502372, 502400],\n",
    "    [564199, 564227]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ventanas**\n",
    "\n",
    "Por EDA se obtiene una posible escala para la división de la ventana de tiempo. Esta corresponde entre 10.000 y 13.500 pts por ventana.\n",
    "Por lo mismo, las ventanas se harán de 10.000pts con un overlap de 1.500 pts por lado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(df, size = 4000, overlap = 500):\n",
    "    num_windows = (len(df) - size) // (size - overlap) + 1\n",
    "    windows = []\n",
    "    for i in range(num_windows):\n",
    "        start = i * (size - overlap)\n",
    "        end = start + size\n",
    "        window = df.iloc[start:end]\n",
    "        windows.append(window)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_windows(start_end_defectos, windows):\n",
    "    result = []\n",
    "    for start, end in start_end_defectos:\n",
    "        for i, window in enumerate(windows):\n",
    "            if start >= window.index[0] and end <= window.index[-1]:\n",
    "                result.append(i)\n",
    "                break\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = create_windows(df)\n",
    "window_indices = find_windows(start_end_defectos, windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **frames for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from windows to dataframe\n",
    "def data_for_model(windows):\n",
    "    wframe = []\n",
    "    for window in windows:\n",
    "        a = window['Gradient Phase'].values\n",
    "        b = window['Amplitude Envelope'].values\n",
    "        c = np.concatenate((a, b), axis=0)\n",
    "        wframe.append(c)\n",
    "\n",
    "    wframe = pd.DataFrame(wframe)\n",
    "    return wframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wframe = data_for_model(windows)\n",
    "unique_indices = np.unique(window_indices)\n",
    "wframe['label'] = np.where(wframe.index.isin(unique_indices), 1, 0)\n",
    "wframe_no_labels = wframe.drop('label', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Split the dataframe into 70% training and 30% testing subsets\n",
    "train_df, test_df = train_test_split(wframe, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create an instance of SVC\n",
    "svm = SVC()\n",
    "\n",
    "# Fit the model to the training data\n",
    "svm.fit(train_df.drop('label', axis=1), train_df['label'])\n",
    "\n",
    "# Predict the labels for the testing data\n",
    "predictions = svm.predict(test_df.drop('label', axis=1))\n",
    "\n",
    "# Print the shapes of the subsets\n",
    "print(\"Training subset shape:\", train_df.shape)\n",
    "print(\"Testing subset shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(test_df['label'], predictions, normalize='true')\n",
    "\n",
    "# Plot the confusion matrix\n",
    "sns.heatmap(np.round(cm, 3), annot=True, cmap='Blues', fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print the classification report\n",
    "report = classification_report(test_df['label'], predictions)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_indices = test_df.index[test_df['label'] != predictions]\n",
    "print(wrong_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in wrong_indices:\n",
    "    subset = windows[ind]\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=subset.index, y=subset['Amplitude Envelope'], name='Amplitude Envelope'))\n",
    "    fig.add_trace(go.Scatter(x=subset.index, y=subset['Gradient Phase'], name='Gradient Phase'))\n",
    "    fig.add_trace(go.Scatter(x=subset.index, y=subset['Filtered Signal'], name='Signal'))\n",
    "    fig.update_layout(title='Index: ' + str(ind))\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, algoritmo se equivoca en zonas con 2 o más defectos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Probar en otra señal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "fpath = \"/Users/granosftp/Documents/GitHub/Tesis/data/\"\n",
    "fname = \"datosconsu_021023_medio_1.mat\"\n",
    "cutoff = [8/1000, 11/1000]\n",
    "\n",
    "set =  ds.MatFileToDataFrame(fpath, fname)\n",
    "df_medios = set.get_dataframe(cutoff)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude_env = np.abs(df_medios['Hilbert Transform'])\n",
    "inst_phase =  np.unwrap(np.angle(df_medios['Hilbert Transform']))\n",
    "inst_freq = (np.diff(inst_phase)/(2.0*np.pi)*1000)\n",
    "diff_phase =  np.diff(inst_phase)\n",
    "mean_phase = np.mean(diff_phase)\n",
    "diff_phase = np.insert(diff_phase, 0, 0)  \n",
    "df_medios['Amplitude Envelope'] = amplitude_env\n",
    "df_medios['Instantaneous Phase'] = inst_phase\n",
    "\n",
    "#filtro al gradiente de fase\n",
    "\n",
    "cutoff = 0.1\n",
    "order = 4\n",
    "\n",
    "b,a = signal.butter(order, cutoff, btype='low')\n",
    "grad_phase = signal.filtfilt(b, a, diff_phase-mean_phase)\n",
    "\n",
    "df_medios['Gradient Phase'] = grad_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_medios = create_windows(df_medios)\n",
    "test_medios = data_for_model(windows_medios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.predict(test_medios)\n",
    "print(svm.predict(test_medios))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "claramente no funciona para otra señal, ya que el modelo está entrenado para la señal previa. Se puede agregar los defectos de esta señal a mano, para mejorar el rendimiento, sin embargo no asegura que vaya a funcionar a mayor escala. Lo bueno, es que por ahora la regla de decisión, al menos visual, esta bien definida, por lo que aumentar la data no es dificil.\n",
    "Para mejores resultados, hay que agregar más data, ajustar los hiperparametros de la red y ver otros modelos (red neuronal, para agregar dimesionalidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_amp = np.min(df_medios['Amplitude Envelope'])\n",
    "indices =  df_medios[df_medios['Amplitude Envelope'] <= min_amp*30].index\n",
    "len(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peaks\n",
    "\n",
    "peak, peak_info = signal.find_peaks(np.abs(df_medios['Gradient Phase']), height=[0, 5.0], distance=10)\n",
    "\n",
    "print(f'Nº de peaks: \\t {len(peak)}')\n",
    "print(f'Amplitud promedio: \\t {np.mean(peak_info[\"peak_heights\"])}')\n",
    "print(f'Amplitud máxima: \\t {np.max(peak_info[\"peak_heights\"])}')\n",
    "print(f'Amplitud mínima: \\t {np.min(peak_info[\"peak_heights\"])}')\n",
    "print(f'Amplitud STD: \\t {np.std(peak_info[\"peak_heights\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intersección\n",
    "intersection = np.intersect1d(indices, peak, assume_unique=False, return_indices=False)\n",
    "len(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **plot defectos medios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, i in enumerate(intersection[:10]):\n",
    "   fig =  go.Figure()\n",
    "   #fig.add_trace(go.Scatter(x = df.index[i-500:i+500], y = amp_filtered[i-500:i+500], name='AE Filtrada'))#, line_shape='linear'))\n",
    "   fig.add_trace(go.Scatter(x = df_medios.index[i-500:i+500], y = (df_medios['Filtered Signal'][i-500:i+500]), name='Filtered Signal'))#, line_shape = 'linear'))']))\n",
    "   fig.add_trace(go.Scatter(x = df_medios.index[i-500:i+500], y = (np.abs(df_medios['Gradient Phase'][i-500:i+500])), name='Gradiente Fase'))\n",
    "   fig.add_trace(go.Scatter(x = df_medios.index[i-500:i+500], y = df_medios['Amplitude Envelope'][i-500:i+500], name='AE'))#, line_shape='linear'))\n",
    "   #fig.add_trace(go.Scatter(x = df.index[i-500:i+500], y = amp_filtered2[i-500:i+500], name='AE Filtrada2'))\n",
    "   fig.update_layout(title = f'Peak indice {i}, curva {k}')\n",
    "   fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min1_medios = []\n",
    "min2_medios = []\n",
    "\n",
    "for i in intersection:\n",
    "    min1 = np.argmin(np.abs(df_medios['Gradient Phase'][i-15:i]))\n",
    "    min2 = np.argmin(np.abs(df_medios['Gradient Phase'][i:i+15]))\n",
    "    min1_medios.append(min1+i-15)\n",
    "    min2_medios.append(min2+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_tau = []\n",
    "for i in range(len(intersection)):\n",
    "    x = intersection[i]\n",
    "    y = min2_medios[i]\n",
    "\n",
    "    num1 = np.abs(df_medios['Gradient Phase'][x])/2\n",
    "    subset = np.abs(df_medios['Gradient Phase'][x:y])\n",
    "    num2 = find_nearest(subset, num1)\n",
    "\n",
    "    indice2 = subset[np.abs(subset == num2)].index[0]\n",
    "    indices_tau.append(indice2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medios_tiempos = pd.DataFrame()\n",
    "df_medios_tiempos['peak'] = intersection\n",
    "\n",
    "df_medios_tiempos['inicio_peak'] = min1_medios\n",
    "df_medios_tiempos['fin_peak'] = min2_medios\n",
    "df_medios_tiempos['duration'] = df_medios_tiempos['fin_peak'] - df_medios_tiempos['inicio_peak']\n",
    "df_medios_tiempos['duration_seg'] = df_medios_tiempos['duration']/1000\n",
    "\n",
    "df_medios_tiempos['peak/2'] = indices_tau\n",
    "df_medios_tiempos['tau_samples'] = df_medios_tiempos['peak/2'] - df_medios_tiempos['peak']\n",
    "df_medios_tiempos['tau_seg'] = df_medios_tiempos['tau_samples']/1000\n",
    "\n",
    "df_medios_tiempos['difference'] = df_medios_tiempos['inicio_peak'].shift(-1) - df_medios_tiempos['fin_peak']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medios_tiempos[['duration', 'tau_samples', 'difference']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, se pueden hacer ventanas de 2.000 puntos cada una, con un overlap de 500 puntos. Con esto me aseguro de que menos del 30% de las ventanas con defectos presenten defectos dobles y las ventanas que presentan defectos dobles, se puede dividir en dos y se les hace padding para rellenar y obtener 3 datos de esa, que correspondería a al ventana con defectos dobles, ventan con defecto 1 y ventana con defecto 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **decomposición de las señales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from scipy.fft import fft, rfft\n",
    "from scipy.fft import fftfreq, rfftfreq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **amplitud media**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_decompose = seasonal_decompose(df_medios['Amplitude Envelope'], model='aditive', period=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = mid_decompose.trend.index, y = mid_decompose.trend, name='Trend'))\n",
    "fig.add_trace(go.Scatter(x = mid_decompose.seasonal.index, y = mid_decompose.seasonal, name='Seasonal'))\n",
    "fig.add_trace(go.Scatter(x = mid_decompose.resid.index, y = mid_decompose.resid, name='Residual'))\n",
    "fig.update_layout(title = 'Descomposición de la señal')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_mid = mid_decompose.seasonal.values\n",
    "fft_season_mid = fft(season_mid)\n",
    "sampling_rate = 1000.0\n",
    "N = len(season_mid)\n",
    "\n",
    "normalize = N/2.0\n",
    "\n",
    "freq_axis = fftfreq(N, d=1.0/sampling_rate)\n",
    "norm_amplitude = np.abs(fft_season_mid)/normalize\n",
    "normalize = N/2.0\n",
    "\n",
    "freq_axis = fftfreq(N, d = 1.0/sampling_rate)\n",
    "norm_amplitude = np.abs(fft_season_mid)/normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=freq_axis, y=norm_amplitude, mode='lines'))\n",
    "fig.update_layout(title='Espectro AE estacional', xaxis_title='Frequency [Hz]', yaxis_title='Amplitude')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La onda envolvente, presenta una fuerte estacionalidad, que tiene como frecuencias dominantes de 1 a 7 Hz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **amplitud baja**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_decompose = seasonal_decompose(df['Amplitude Envelope'], model='aditive', period=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = low_decompose.trend.index, y = low_decompose.trend, name='Trend'))\n",
    "fig.add_trace(go.Scatter(x = low_decompose.seasonal.index, y = low_decompose.seasonal, name='Seasonal'))\n",
    "fig.add_trace(go.Scatter(x = low_decompose.resid.index, y = low_decompose.resid, name='Residual'))\n",
    "fig.update_layout(title = 'Descomposición de la señal (baja amplitud)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fft_season_low = fft(low_decompose.seasonal.values)\n",
    "sampling_rate = 1000.0\n",
    "N = len(low_decompose.seasonal.values)\n",
    "\n",
    "normalize = N/2.0\n",
    "\n",
    "freq_axis = fftfreq(N, d=1.0/sampling_rate)\n",
    "norm_amplitude = np.abs(fft_season_low)/normalize\n",
    "normalize = N/2.0\n",
    "\n",
    "freq_axis = fftfreq(N, d = 1.0/sampling_rate)\n",
    "norm_amplitude = np.abs(fft_season_low)/normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=freq_axis, y=norm_amplitude, mode='lines'))\n",
    "fig.update_layout(title='Espectro AE estacional', xaxis_title='Frequency [Hz]', yaxis_title='Amplitude')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
