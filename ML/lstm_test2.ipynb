{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files\n",
    "import sys\n",
    "from os import listdir\n",
    "sys.path.append('../data')\n",
    "sys.path.append('../Librerias')\n",
    "from os.path import isfile, join\n",
    "\n",
    "#own libs\n",
    "import utils\n",
    "import caract as dc\n",
    "import dataset as ds\n",
    "\n",
    "\n",
    "#data and visualization\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "\n",
    "# univariate multi-step encoder-decoder lstm\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file10_080124.mat\n",
      "file11_080124.mat\n",
      "file12_080124.mat\n",
      "file13_080124.mat\n",
      "file15_080124.mat\n",
      "file16_080124.mat\n",
      "file17_080124.mat\n",
      "file18_080124.mat\n",
      "file1_050124.mat\n",
      "file1_080124.mat\n",
      "file2_050124.mat\n",
      "file3_080124.mat\n",
      "file7_080124.mat\n",
      "file8_080124.mat\n",
      "file9_080124.mat\n",
      "low1_100124.mat\n",
      "low2_100124.mat\n",
      "low3_100124.mat\n",
      "low5_100124.mat\n",
      "1\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Signal</th>\n",
       "      <th>Signal - Mean</th>\n",
       "      <th>Filtered Signal</th>\n",
       "      <th>Hilbert Transform</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>Instantaneous Phase</th>\n",
       "      <th>Gradient Phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.076967</td>\n",
       "      <td>-0.041045</td>\n",
       "      <td>-0.005045</td>\n",
       "      <td>-0.005045+0.003866j</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>2.487745</td>\n",
       "      <td>-0.050221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076638</td>\n",
       "      <td>-0.041374</td>\n",
       "      <td>-0.004841</td>\n",
       "      <td>-0.004841+0.000279j</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>3.083952</td>\n",
       "      <td>-0.023636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073022</td>\n",
       "      <td>-0.044991</td>\n",
       "      <td>-0.004633</td>\n",
       "      <td>-0.004633+0.000083j</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>3.123610</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073022</td>\n",
       "      <td>-0.044991</td>\n",
       "      <td>-0.004421</td>\n",
       "      <td>-0.004421-0.001203j</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>3.407171</td>\n",
       "      <td>0.023619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.071378</td>\n",
       "      <td>-0.046635</td>\n",
       "      <td>-0.004205</td>\n",
       "      <td>-0.004205-0.001356j</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>3.453607</td>\n",
       "      <td>0.041826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>0.176268</td>\n",
       "      <td>0.058256</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015+0.000493j</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>30135.697377</td>\n",
       "      <td>-0.289769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>0.177254</td>\n",
       "      <td>0.059242</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000033+0.000343j</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>30135.630801</td>\n",
       "      <td>-0.245612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>0.179227</td>\n",
       "      <td>0.061215</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050+0.001284j</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>30135.688260</td>\n",
       "      <td>-0.187389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>0.179885</td>\n",
       "      <td>0.061872</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000066+0.001095j</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>30135.667052</td>\n",
       "      <td>-0.118399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>0.180213</td>\n",
       "      <td>0.062201</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081+0.004177j</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>30135.708199</td>\n",
       "      <td>-0.042767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Original Signal  Signal - Mean  Filtered Signal   Hilbert Transform  \\\n",
       "0              0.076967      -0.041045        -0.005045 -0.005045+0.003866j   \n",
       "1              0.076638      -0.041374        -0.004841 -0.004841+0.000279j   \n",
       "2              0.073022      -0.044991        -0.004633 -0.004633+0.000083j   \n",
       "3              0.073022      -0.044991        -0.004421 -0.004421-0.001203j   \n",
       "4              0.071378      -0.046635        -0.004205 -0.004205-0.001356j   \n",
       "...                 ...            ...              ...                 ...   \n",
       "599995         0.176268       0.058256         0.000015  0.000015+0.000493j   \n",
       "599996         0.177254       0.059242         0.000033  0.000033+0.000343j   \n",
       "599997         0.179227       0.061215         0.000050  0.000050+0.001284j   \n",
       "599998         0.179885       0.061872         0.000066  0.000066+0.001095j   \n",
       "599999         0.180213       0.062201         0.000081  0.000081+0.004177j   \n",
       "\n",
       "        Amplitude  Instantaneous Phase  Gradient Phase  \n",
       "0        0.006356             2.487745       -0.050221  \n",
       "1        0.004849             3.083952       -0.023636  \n",
       "2        0.004634             3.123610        0.001438  \n",
       "3        0.004582             3.407171        0.023619  \n",
       "4        0.004419             3.453607        0.041826  \n",
       "...           ...                  ...             ...  \n",
       "599995   0.000493         30135.697377       -0.289769  \n",
       "599996   0.000345         30135.630801       -0.245612  \n",
       "599997   0.001285         30135.688260       -0.187389  \n",
       "599998   0.001097         30135.667052       -0.118399  \n",
       "599999   0.004178         30135.708199       -0.042767  \n",
       "\n",
       "[600000 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fpath = \"/Users/granosftp/Documents/GitHub/Tesis/data/high/\"\n",
    "fpath =  \"/Users/consu/OneDrive/Documentos/GitHub/Tesis/data/low/\"\n",
    "onlyfiles = [f for f in listdir(fpath) if isfile(join(fpath, f))]\n",
    "\n",
    "cutoff = [8/1000, 11/1000]\n",
    "\n",
    "#load data\n",
    "frames = []\n",
    "for fname in onlyfiles:\n",
    "    if fname.endswith(\".mat\"):\n",
    "        set =  ds.MatFileToDataFrame(fpath, fname)\n",
    "        df = set.get_dataframe(cutoff)\n",
    "        frames.append(df)\n",
    "        print(fname)\n",
    "\n",
    "frames = frames[:2]\n",
    "\n",
    "defectos_frames = []\n",
    "taus = []\n",
    "for i, df in enumerate(frames):\n",
    "    aux = dc.CaractDefect(df)\n",
    "    defectos_frames.append(aux)\n",
    "    taus.append(aux.get_tau()[1])\n",
    "    sys.stdout.write(str(i) + '\\r')\n",
    "\n",
    "\n",
    "hilbert_frames = []\n",
    "for i, df in enumerate(defectos_frames):\n",
    "    aux, _ = df.get_hilbert()\n",
    "    hilbert_frames.append(aux)\n",
    "    sys.stdout.write(str(i) + '\\r')\n",
    "\n",
    "\n",
    "frames_all = []\n",
    "\n",
    "for i in range(len(frames)):\n",
    "    frames_all.append(pd.merge(frames[i], hilbert_frames[i], on='Hilbert Transform', how='outer'))\n",
    "\n",
    "frames_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = frames_all[0]\n",
    "def split_dataset(data):\n",
    "    train, test = data['Amplitude'][:10000], data['Amplitude'][10000:20000]\n",
    "    train = array(split(train, len(train)/50))\n",
    "    test = array(split(test, len(test)/50))\n",
    "    return np.expand_dims(train, 2), np.expand_dims(test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 50, 1), (200, 50, 1))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = split_dataset(df)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forecast(actual, predicted):\n",
    "    scores = list() #for each prediction\n",
    "\n",
    "    for i in range(actual.shape[1]):\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        rmse = sqrt(mse)\n",
    "        score.append(rmse)\n",
    "\n",
    "    S = 0 #overall rmse\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            S += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(S/(actual.shape[0]*actual.shape[1]))\n",
    "\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_supervise(train, n_inputs, n_outputs = 10):\n",
    "    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "\n",
    "    for _ in range(len(data)):\n",
    "        in_end = in_start + n_inputs\n",
    "        out_end = in_end + n_outputs\n",
    "\n",
    "        if out_end <= len(data):\n",
    "            X.append(data[in_start:in_end, :])\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "        in_start += 1\n",
    "\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(train, n_input):\n",
    "    train_x, train_y = to_supervise(train, n_input)\n",
    "    verbose, epochs, batch_size = 1, 10, 32\n",
    "    n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "\n",
    "    #define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    #fit network\n",
    "    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model, history, n_input):\n",
    "    #flatten data\n",
    "    data = array(history)\n",
    "    data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "    #retrieve last observations\n",
    "    input_x = data[-n_input:, :0]\n",
    "    #reshape into [1, n_input, n]\n",
    "    input_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
    "    \n",
    "    #forecast the next 50\n",
    "    yhat = model.predict(input_x, verbose=0)\n",
    "    yhat = yhat[0]\n",
    "    return yhat\n",
    "\n",
    "def evaluate_model(train, test, n_input):\n",
    "    model = build_model(train, n_input)\n",
    "    history = [x for x in train]\n",
    "    predictions = list()\n",
    "\n",
    "    for i in range(len(test)):\n",
    "        yhat_sequence = forecast(model, history, n_input)\n",
    "        predictions.append(yhat_sequence)\n",
    "        history.append(test[i, :])\n",
    "\n",
    "    predictions = array(predictions)\n",
    "    #score, scores = evaluate_forecast(test[:, :, 0], predictions)\n",
    "    return model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "308/308 [==============================] - 54s 167ms/step - loss: 2.9434e-07\n",
      "Epoch 2/10\n",
      "308/308 [==============================] - 51s 166ms/step - loss: 1.9541e-07\n",
      "Epoch 3/10\n",
      "308/308 [==============================] - 52s 168ms/step - loss: 1.9410e-07\n",
      "Epoch 4/10\n",
      "308/308 [==============================] - 57s 184ms/step - loss: 2.0938e-07\n",
      "Epoch 5/10\n",
      "308/308 [==============================] - 51s 166ms/step - loss: 2.2397e-07\n",
      "Epoch 6/10\n",
      "308/308 [==============================] - 50s 162ms/step - loss: 1.9981e-07\n",
      "Epoch 7/10\n",
      "308/308 [==============================] - 53s 171ms/step - loss: 1.8182e-07\n",
      "Epoch 8/10\n",
      "308/308 [==============================] - 55s 178ms/step - loss: 1.8462e-07\n",
      "Epoch 9/10\n",
      "308/308 [==============================] - 57s 184ms/step - loss: 1.7526e-07\n",
      "Epoch 10/10\n",
      "308/308 [==============================] - 55s 178ms/step - loss: 1.9137e-07\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_6' (type Sequential).\n    \n    Input 0 of layer \"lstm_12\" is incompatible with the layer: expected shape=(None, None, 1), found shape=(None, 100, 0)\n    \n    Call arguments received by layer 'sequential_6' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 100, 0), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m train, test \u001b[38;5;241m=\u001b[39m split_dataset(df)\n\u001b[0;32m      2\u001b[0m n_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 3\u001b[0m model, predictions \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(train, test, n_input)\u001b[0m\n\u001b[0;32m     18\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test)):\n\u001b[1;32m---> 21\u001b[0m     yhat_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(yhat_sequence)\n\u001b[0;32m     23\u001b[0m     history\u001b[38;5;241m.\u001b[39mappend(test[i, :])\n",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36mforecast\u001b[1;34m(model, history, n_input)\u001b[0m\n\u001b[0;32m      8\u001b[0m input_x \u001b[38;5;241m=\u001b[39m input_x\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, input_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], input_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#forecast the next 50\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m yhat \u001b[38;5;241m=\u001b[39m yhat[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m yhat\n",
      "File \u001b[1;32mc:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filex3j0bist.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_6' (type Sequential).\n    \n    Input 0 of layer \"lstm_12\" is incompatible with the layer: expected shape=(None, None, 1), found shape=(None, 100, 0)\n    \n    Call arguments received by layer 'sequential_6' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 100, 0), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "train, test = split_dataset(df)\n",
    "n_input = 100\n",
    "model, predictions = evaluate_model(train, test, n_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **este funciona perooo**\n",
    "\n",
    "hay una cosa rara en los test de predicción, hay que ver si la predicción y el actual sean de la misma dimensión y hay que arreglar ese problema porque tecnicamente esta malo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm: [0.001] 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (7,) and (10,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [79]\u001b[0m, in \u001b[0;36m<cell line: 97>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# plot scores\u001b[39;00m\n\u001b[0;32m     96\u001b[0m days \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msun\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfri\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msat\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 97\u001b[0m \u001b[43mpyplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlstm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m pyplot\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\pyplot.py:3578\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3570\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3572\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3576\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3577\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   3579\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   3580\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[0;32m   3581\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   3582\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   3583\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3584\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (7,) and (10,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# univariate multi-step encoder-decoder lstm\n",
    "from math import sqrt\n",
    "from numpy import split, array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, RepeatVector, TimeDistributed\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "    train_size = 10000\n",
    "    train, test = data[:train_size], data[train_size:train_size+50]  # Adjusted for a forecast horizon of 50 steps\n",
    "    train = array(split(train, len(train) // 10))\n",
    "    test = array(split(test, len(test) // 10))\n",
    "    return train, test\n",
    "\n",
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = [sqrt(mean_squared_error(actual[:, i], predicted[:, i])) for i in range(actual.shape[1])]\n",
    "    score = sqrt(((actual - predicted) ** 2).mean())\n",
    "    return score, scores\n",
    "\n",
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "    s_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "    print('%s: [%.3f] %s' % (name, score, s_scores))\n",
    "\n",
    "# convert history into inputs and outputs\n",
    "def to_supervised(train, n_input, n_out=7):\n",
    "    data = train.reshape((train.shape[0] * train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    for _ in range(len(data)):\n",
    "        in_end, out_end = in_start + n_input, in_start + n_input + n_out\n",
    "        if out_end <= len(data):\n",
    "            x_input = data[in_start:in_end, 0]\n",
    "            x_input = x_input.reshape((len(x_input), 1))\n",
    "            X.append(x_input)\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "        in_start += 1\n",
    "    return array(X), array(y)\n",
    "\n",
    "# train the model\n",
    "def build_model(train, n_input):\n",
    "    train_x, train_y = to_supervised(train, n_input, 50)  # Adjusted for a forecast horizon of 50 steps\n",
    "    verbose, epochs, batch_size = 0, 20, 16\n",
    "    n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "    train_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    return model\n",
    "\n",
    "# make a forecast\n",
    "def forecast(model, history, n_input):\n",
    "    data = array(history)\n",
    "    data = data.reshape((data.shape[0] * data.shape[1], data.shape[2]))\n",
    "    input_x = data[-n_input:, 0]\n",
    "    input_x = input_x.reshape((1, len(input_x), 1))\n",
    "    yhat = model.predict(input_x, verbose=0)\n",
    "    yhat = yhat[0]\n",
    "    return yhat\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(train, test, n_input):\n",
    "    model = build_model(train, n_input)\n",
    "    history = [x for x in train]\n",
    "    predictions = list()\n",
    "    for i in range(len(test)):\n",
    "        yhat_sequence = forecast(model, history, n_input)\n",
    "        predictions.append(yhat_sequence)\n",
    "        history.append(test[i, :])\n",
    "    predictions = array(predictions)\n",
    "    score, scores = evaluate_forecasts(test[:, :, 0], predictions[:,:10].squeeze())\n",
    "    return model, predictions, score, scores\n",
    "\n",
    "# load the new file\n",
    "#dataset = read_csv('your_dataframe.csv')  # Replace 'your_dataframe.csv' with your actual file path\n",
    "data = df['Amplitude'].values.reshape(-1, 1)  # Assuming 'Amplitude' is the column name\n",
    "# include 10,000 points for training\n",
    "train_data = data[:10000].reshape(-1, 1)\n",
    "# split into train and test\n",
    "train, test = split_dataset(data)\n",
    "# evaluate model and get scores\n",
    "n_input = 14\n",
    "score, scores = evaluate_model(train, test, n_input)\n",
    "# summarize scores\n",
    "summarize_scores('lstm', score, scores)\n",
    "# plot scores\n",
    "#days = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
    "#pyplot.plot(days, scores, marker='o', label='lstm')\n",
    "#pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0009360343632841807,\n",
       " 0.0009199207585673672,\n",
       " 0.0009037461661097017,\n",
       " 0.000887293137228597,\n",
       " 0.0008707818636225401,\n",
       " 0.0008540289187968372,\n",
       " 0.0008372218280725868,\n",
       " 0.0008202113321730752,\n",
       " 0.0008031524218066071,\n",
       " 0.0007859299002905969]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
