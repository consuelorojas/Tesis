{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files\n",
    "import sys\n",
    "from os import listdir\n",
    "sys.path.append('../data')\n",
    "sys.path.append('../Librerias')\n",
    "from os.path import isfile, join\n",
    "\n",
    "#own libs\n",
    "import utils\n",
    "import caract as dc\n",
    "import dataset as ds\n",
    "\n",
    "\n",
    "#data and visualization\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "\n",
    "# univariate multi-step encoder-decoder lstm\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file10_080124.mat\n",
      "file11_080124.mat\n",
      "file12_080124.mat\n",
      "file13_080124.mat\n",
      "file15_080124.mat\n",
      "file16_080124.mat\n",
      "file17_080124.mat\n",
      "file18_080124.mat\n",
      "file1_050124.mat\n",
      "file1_080124.mat\n",
      "file2_050124.mat\n",
      "file3_080124.mat\n",
      "file7_080124.mat\n",
      "file8_080124.mat\n",
      "file9_080124.mat\n",
      "low1_100124.mat\n",
      "low2_100124.mat\n",
      "low3_100124.mat\n",
      "low5_100124.mat\n",
      "1\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Signal</th>\n",
       "      <th>Signal - Mean</th>\n",
       "      <th>Filtered Signal</th>\n",
       "      <th>Hilbert Transform</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>Instantaneous Phase</th>\n",
       "      <th>Gradient Phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.076967</td>\n",
       "      <td>-0.041045</td>\n",
       "      <td>-0.005045</td>\n",
       "      <td>-0.005045+0.003866j</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>2.487745</td>\n",
       "      <td>-0.050221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076638</td>\n",
       "      <td>-0.041374</td>\n",
       "      <td>-0.004841</td>\n",
       "      <td>-0.004841+0.000279j</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>3.083952</td>\n",
       "      <td>-0.023636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073022</td>\n",
       "      <td>-0.044991</td>\n",
       "      <td>-0.004633</td>\n",
       "      <td>-0.004633+0.000083j</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>3.123610</td>\n",
       "      <td>0.001438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073022</td>\n",
       "      <td>-0.044991</td>\n",
       "      <td>-0.004421</td>\n",
       "      <td>-0.004421-0.001203j</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>3.407171</td>\n",
       "      <td>0.023619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.071378</td>\n",
       "      <td>-0.046635</td>\n",
       "      <td>-0.004205</td>\n",
       "      <td>-0.004205-0.001356j</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>3.453607</td>\n",
       "      <td>0.041826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>0.176268</td>\n",
       "      <td>0.058256</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015+0.000493j</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>30135.697377</td>\n",
       "      <td>-0.289769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>0.177254</td>\n",
       "      <td>0.059242</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000033+0.000343j</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>30135.630801</td>\n",
       "      <td>-0.245612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>0.179227</td>\n",
       "      <td>0.061215</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000050+0.001284j</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>30135.688260</td>\n",
       "      <td>-0.187389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>0.179885</td>\n",
       "      <td>0.061872</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000066+0.001095j</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>30135.667052</td>\n",
       "      <td>-0.118399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>0.180213</td>\n",
       "      <td>0.062201</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081+0.004177j</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>30135.708199</td>\n",
       "      <td>-0.042767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Original Signal  Signal - Mean  Filtered Signal   Hilbert Transform  \\\n",
       "0              0.076967      -0.041045        -0.005045 -0.005045+0.003866j   \n",
       "1              0.076638      -0.041374        -0.004841 -0.004841+0.000279j   \n",
       "2              0.073022      -0.044991        -0.004633 -0.004633+0.000083j   \n",
       "3              0.073022      -0.044991        -0.004421 -0.004421-0.001203j   \n",
       "4              0.071378      -0.046635        -0.004205 -0.004205-0.001356j   \n",
       "...                 ...            ...              ...                 ...   \n",
       "599995         0.176268       0.058256         0.000015  0.000015+0.000493j   \n",
       "599996         0.177254       0.059242         0.000033  0.000033+0.000343j   \n",
       "599997         0.179227       0.061215         0.000050  0.000050+0.001284j   \n",
       "599998         0.179885       0.061872         0.000066  0.000066+0.001095j   \n",
       "599999         0.180213       0.062201         0.000081  0.000081+0.004177j   \n",
       "\n",
       "        Amplitude  Instantaneous Phase  Gradient Phase  \n",
       "0        0.006356             2.487745       -0.050221  \n",
       "1        0.004849             3.083952       -0.023636  \n",
       "2        0.004634             3.123610        0.001438  \n",
       "3        0.004582             3.407171        0.023619  \n",
       "4        0.004419             3.453607        0.041826  \n",
       "...           ...                  ...             ...  \n",
       "599995   0.000493         30135.697377       -0.289769  \n",
       "599996   0.000345         30135.630801       -0.245612  \n",
       "599997   0.001285         30135.688260       -0.187389  \n",
       "599998   0.001097         30135.667052       -0.118399  \n",
       "599999   0.004178         30135.708199       -0.042767  \n",
       "\n",
       "[600000 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fpath = \"/Users/granosftp/Documents/GitHub/Tesis/data/high/\"\n",
    "fpath =  \"/Users/consu/OneDrive/Documentos/GitHub/Tesis/data/low/\"\n",
    "onlyfiles = [f for f in listdir(fpath) if isfile(join(fpath, f))]\n",
    "\n",
    "cutoff = [8/1000, 11/1000]\n",
    "\n",
    "#load data\n",
    "frames = []\n",
    "for fname in onlyfiles:\n",
    "    if fname.endswith(\".mat\"):\n",
    "        set =  ds.MatFileToDataFrame(fpath, fname)\n",
    "        df = set.get_dataframe(cutoff)\n",
    "        frames.append(df)\n",
    "        print(fname)\n",
    "\n",
    "frames = frames[:2]\n",
    "\n",
    "defectos_frames = []\n",
    "taus = []\n",
    "for i, df in enumerate(frames):\n",
    "    aux = dc.CaractDefect(df)\n",
    "    defectos_frames.append(aux)\n",
    "    taus.append(aux.get_tau()[1])\n",
    "    sys.stdout.write(str(i) + '\\r')\n",
    "\n",
    "\n",
    "hilbert_frames = []\n",
    "for i, df in enumerate(defectos_frames):\n",
    "    aux, _ = df.get_hilbert()\n",
    "    hilbert_frames.append(aux)\n",
    "    sys.stdout.write(str(i) + '\\r')\n",
    "\n",
    "\n",
    "frames_all = []\n",
    "\n",
    "for i in range(len(frames)):\n",
    "    frames_all.append(pd.merge(frames[i], hilbert_frames[i], on='Hilbert Transform', how='outer'))\n",
    "\n",
    "frames_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = frames_all[0]\n",
    "def split_dataset(data):\n",
    "    train, test = data['Amplitude'][:10000], data['Amplitude'][10000:20000]\n",
    "    train = array(split(train, len(train)/50))\n",
    "    test = array(split(test, len(test)/50))\n",
    "    return np.expand_dims(train, 2), np.expand_dims(test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 50, 1), (200, 50, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = split_dataset(df)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forecast(actual, predicted):\n",
    "    scores = list() #for each prediction\n",
    "\n",
    "    for i in range(actual.shape[1]):\n",
    "        mse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        rmse = sqrt(mse)\n",
    "        score.append(rmse)\n",
    "\n",
    "    S = 0 #overall rmse\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            S += (actual[row, col] - predicted[row, col])**2\n",
    "    score = sqrt(S/(actual.shape[0]*actual.shape[1]))\n",
    "\n",
    "    return score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_supervise(train, n_inputs, n_outputs = 10):\n",
    "    data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "\n",
    "    for _ in range(len(data)):\n",
    "        in_end = in_start + n_inputs\n",
    "        out_end = in_end + n_outputs\n",
    "\n",
    "        if out_end <= len(data):\n",
    "            X.append(data[in_start:in_end, :])\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "        in_start += 1\n",
    "\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(train, n_input):\n",
    "    train_x, train_y = to_supervise(train, n_input)\n",
    "    verbose, epochs, batch_size = 1, 10, 32\n",
    "    n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "\n",
    "    #define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    #fit network\n",
    "    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model, history, n_input):\n",
    "    #flatten data\n",
    "    data = array(history)\n",
    "    data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "    #retrieve last observations\n",
    "    input_x = data[-n_input:, :0]\n",
    "    #reshape into [1, n_input, n]\n",
    "    input_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
    "    \n",
    "    #forecast the next 50\n",
    "    yhat = model.predict(input_x, verbose=0)\n",
    "    yhat = yhat[0]\n",
    "    return yhat\n",
    "\n",
    "def evaluate_model(train, test, n_input):\n",
    "    model = build_model(train, n_input)\n",
    "    history = [x for x in train]\n",
    "    predictions = list()\n",
    "\n",
    "    for i in range(len(test)):\n",
    "        yhat_sequence = forecast(model, history, n_input)\n",
    "        predictions.append(yhat_sequence)\n",
    "        history.append(test[i, :])\n",
    "\n",
    "    predictions = array(predictions)\n",
    "    #score, scores = evaluate_forecast(test[:, :, 0], predictions)\n",
    "    return model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "308/308 [==============================] - 54s 167ms/step - loss: 2.9434e-07\n",
      "Epoch 2/10\n",
      "308/308 [==============================] - 51s 166ms/step - loss: 1.9541e-07\n",
      "Epoch 3/10\n",
      "308/308 [==============================] - 52s 168ms/step - loss: 1.9410e-07\n",
      "Epoch 4/10\n",
      "308/308 [==============================] - 57s 184ms/step - loss: 2.0938e-07\n",
      "Epoch 5/10\n",
      "308/308 [==============================] - 51s 166ms/step - loss: 2.2397e-07\n",
      "Epoch 6/10\n",
      "308/308 [==============================] - 50s 162ms/step - loss: 1.9981e-07\n",
      "Epoch 7/10\n",
      "308/308 [==============================] - 53s 171ms/step - loss: 1.8182e-07\n",
      "Epoch 8/10\n",
      "308/308 [==============================] - 55s 178ms/step - loss: 1.8462e-07\n",
      "Epoch 9/10\n",
      "308/308 [==============================] - 57s 184ms/step - loss: 1.7526e-07\n",
      "Epoch 10/10\n",
      "308/308 [==============================] - 55s 178ms/step - loss: 1.9137e-07\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_6' (type Sequential).\n    \n    Input 0 of layer \"lstm_12\" is incompatible with the layer: expected shape=(None, None, 1), found shape=(None, 100, 0)\n    \n    Call arguments received by layer 'sequential_6' (type Sequential):\n      â€¢ inputs=tf.Tensor(shape=(None, 100, 0), dtype=float32)\n      â€¢ training=False\n      â€¢ mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m train, test \u001b[38;5;241m=\u001b[39m split_dataset(df)\n\u001b[0;32m      2\u001b[0m n_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 3\u001b[0m model, predictions \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(train, test, n_input)\u001b[0m\n\u001b[0;32m     18\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test)):\n\u001b[1;32m---> 21\u001b[0m     yhat_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mforecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(yhat_sequence)\n\u001b[0;32m     23\u001b[0m     history\u001b[38;5;241m.\u001b[39mappend(test[i, :])\n",
      "Input \u001b[1;32mIn [54]\u001b[0m, in \u001b[0;36mforecast\u001b[1;34m(model, history, n_input)\u001b[0m\n\u001b[0;32m      8\u001b[0m input_x \u001b[38;5;241m=\u001b[39m input_x\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, input_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], input_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#forecast the next 50\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m yhat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m yhat \u001b[38;5;241m=\u001b[39m yhat[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m yhat\n",
      "File \u001b[1;32mc:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filex3j0bist.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_6' (type Sequential).\n    \n    Input 0 of layer \"lstm_12\" is incompatible with the layer: expected shape=(None, None, 1), found shape=(None, 100, 0)\n    \n    Call arguments received by layer 'sequential_6' (type Sequential):\n      â€¢ inputs=tf.Tensor(shape=(None, 100, 0), dtype=float32)\n      â€¢ training=False\n      â€¢ mask=None\n"
     ]
    }
   ],
   "source": [
    "train, test = split_dataset(df)\n",
    "n_input = 100\n",
    "model, predictions = evaluate_model(train, test, n_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **este funciona perooo**\n",
    "\n",
    "hay una cosa rara en los test de predicciÃ³n, hay que ver si la predicciÃ³n y el actual sean de la misma dimensiÃ³n y hay que arreglar ese problema porque tecnicamente esta malo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\consu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 92>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# evaluate model and get scores\u001b[39;00m\n\u001b[0;32m     91\u001b[0m n_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m14\u001b[39m\n\u001b[1;32m---> 92\u001b[0m score, scores \u001b[38;5;241m=\u001b[39m evaluate_model(train, test, n_input)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# summarize scores\u001b[39;00m\n\u001b[0;32m     94\u001b[0m summarize_scores(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m'\u001b[39m, score, scores)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# univariate multi-step encoder-decoder lstm\n",
    "from math import sqrt\n",
    "from numpy import split, array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, RepeatVector, TimeDistributed\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "    train_size = 10000\n",
    "    train, test = data[:train_size], data[train_size:train_size+50]  # Adjusted for a forecast horizon of 50 steps\n",
    "    train = array(split(train, len(train) // 10))\n",
    "    test = array(split(test, len(test) // 10))\n",
    "    return train, test\n",
    "\n",
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "    scores = [sqrt(mean_squared_error(actual[:, i], predicted[:, i])) for i in range(actual.shape[1])]\n",
    "    score = sqrt(((actual - predicted) ** 2).mean())\n",
    "    return score, scores\n",
    "\n",
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "    s_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "    print('%s: [%.3f] %s' % (name, score, s_scores))\n",
    "\n",
    "# convert history into inputs and outputs\n",
    "def to_supervised(train, n_input, n_out=7):\n",
    "    data = train.reshape((train.shape[0] * train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    for _ in range(len(data)):\n",
    "        in_end, out_end = in_start + n_input, in_start + n_input + n_out\n",
    "        if out_end <= len(data):\n",
    "            x_input = data[in_start:in_end, 0]\n",
    "            x_input = x_input.reshape((len(x_input), 1))\n",
    "            X.append(x_input)\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "        in_start += 1\n",
    "    return array(X), array(y)\n",
    "\n",
    "# train the model\n",
    "def build_model(train, n_input):\n",
    "    train_x, train_y = to_supervised(train, n_input, 50)  # Adjusted for a forecast horizon of 50 steps\n",
    "    verbose, epochs, batch_size = 0, 20, 16\n",
    "    n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "    train_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "    model.add(RepeatVector(n_outputs))\n",
    "    model.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    return model\n",
    "\n",
    "# make a forecast\n",
    "def forecast(model, history, n_input):\n",
    "    data = array(history)\n",
    "    data = data.reshape((data.shape[0] * data.shape[1], data.shape[2]))\n",
    "    input_x = data[-n_input:, 0]\n",
    "    input_x = input_x.reshape((1, len(input_x), 1))\n",
    "    yhat = model.predict(input_x, verbose=0)\n",
    "    yhat = yhat[0]\n",
    "    return yhat\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(train, test, n_input):\n",
    "    model = build_model(train, n_input)\n",
    "    history = [x for x in train]\n",
    "    predictions = list()\n",
    "    for i in range(len(test)):\n",
    "        yhat_sequence = forecast(model, history, n_input)\n",
    "        predictions.append(yhat_sequence)\n",
    "        history.append(test[i, :])\n",
    "    predictions = array(predictions)\n",
    "    score, scores = evaluate_forecasts(test[:, :, 0], predictions[:,:10].squeeze())\n",
    "    return model, predictions, score, scores\n",
    "\n",
    "# load the new file\n",
    "#dataset = read_csv('your_dataframe.csv')  # Replace 'your_dataframe.csv' with your actual file path\n",
    "data = df['Amplitude'].values.reshape(-1, 1)  # Assuming 'Amplitude' is the column name\n",
    "# include 10,000 points for training\n",
    "train_data = data[:10000].reshape(-1, 1)\n",
    "# split into train and test\n",
    "train, test = split_dataset(data)\n",
    "# evaluate model and get scores\n",
    "n_input = 14\n",
    "modelo, predictions, score, scores = evaluate_model(train, test, n_input)\n",
    "# summarize scores\n",
    "summarize_scores('lstm', score, scores)\n",
    "# plot scores\n",
    "#days = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
    "#pyplot.plot(days, scores, marker='o', label='lstm')\n",
    "#pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot(scores)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(predictions[0,:], label='Predicted')\n",
    "plt.plot(test[0,:], label='Real')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
